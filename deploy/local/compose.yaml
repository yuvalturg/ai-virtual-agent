# AI Virtual Agent - Development Environment
#
# This compose file starts all services needed for local development:
# - PostgreSQL database (always)
# - LlamaStack AI service (always)
# - Backend API (FastAPI) (always)
# - Frontend (React/Vite) (always)
# - MinIO object storage (optional, controlled by ENABLE_ATTACHMENTS)
#
# Environment Variables:
#   ENABLE_ATTACHMENTS=true|false   # Enable/disable MinIO and attachment features
#   DISABLE_ATTACHMENTS=true|false  # Backend env var (set automatically)
#   LOCAL_DEV_ENV_MODE=true|false   # Enable development mode (disables auth)
#
# Usage:
#   make compose-up                             # Start with attachments and dev mode enabled
#   ENABLE_ATTACHMENTS=false make compose-up   # Start without attachments
#   LOCAL_DEV_ENV_MODE=false make compose-up   # Start with auth enabled (production-like)
#   make compose-down                      # Stop all services
#
# Profiles:
#   attachments - MinIO service (only started when ENABLE_ATTACHMENTS=true)
#
services:
  # Database service (existing, enhanced)
  db:
    image: postgres:15
    container_name: postgresql-dev
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-ai_virtual_agent}
      - POSTGRES_USER=${POSTGRES_USER:-admin}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-password}
    ports:
      - '${POSTGRES_PORT:-5432}:5432'
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-admin} -d ${POSTGRES_DB:-ai_virtual_agent}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ai-va-network

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-dev
    ports:
      - '${OLLAMA_PORT:-11434}:11434'
    volumes:
      - ollama:/root/.ollama
    networks:
      - ai-va-network
    entrypoint:
      - bash
      - -c
      - "OLLAMA_DEBUG=1 ollama serve & sleep 10; ollama run llama3.2:1b-instruct-fp16 --keepalive 60m hi; wait"
    healthcheck:
      test: ["CMD-SHELL", "ollama list | grep -q llama3.2:1b-instruct-fp16"]
      interval: 30s
      timeout: 10s
      retries: 30

  # LlamaStack service
  llamastack:
    image: llamastack/distribution-starter:0.3.2
    container_name: llamastack-dev
    platform: linux/amd64
    restart: unless-stopped
    environment:
      - RUN_CONFIG_PATH=/app-config/config.yaml
    ports:
      - '${LLAMASTACK_PORT:-8321}:8321'
    volumes:
      - llama:/.llama
      - llamadist:/.llama/distributions
      - ${PWD}/deploy/local/llamastack-run.yaml:/app-config/config.yaml:Z
    networks:
      - ai-va-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8321/docs || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 30
      start_period: 60s
    depends_on:
      ollama:
        condition: service_healthy

  # Backend service
  backend:
    build:
      context: ../../
      dockerfile: deploy/local/Containerfile.backend.dev
    container_name: ai-va-backend-dev
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql+asyncpg://${POSTGRES_USER:-admin}:${POSTGRES_PASSWORD:-password}@db:5432/${POSTGRES_DB:-ai_virtual_agent}
      - LOCAL_DEV_ENV_MODE=${LOCAL_DEV_ENV_MODE:-true}
      - LLAMASTACK_URL=${LLAMASTACK_URL:-http://llamastack:8321}
      - DISABLE_ATTACHMENTS=${DISABLE_ATTACHMENTS:-false}
    ports:
      - '${BACKEND_PORT:-8000}:8000'
    volumes:
      - ../../backend:/app/backend:Z
    depends_on:
      db:
        condition: service_healthy
      llamastack:
        condition: service_healthy
      minio:
        condition: service_healthy
        required: false
    networks:
      - ai-va-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/docs || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Frontend service
  frontend:
    build:
      context: ../../
      dockerfile: deploy/local/Containerfile.frontend.dev
    container_name: ai-va-frontend-dev
    restart: unless-stopped
    environment:
      - VITE_API_BASE_URL=http://backend:8000
    ports:
      - '${FRONTEND_PORT:-5173}:5173'
    volumes:
      - ../../frontend:/app:Z
      - /app/node_modules
    depends_on:
      backend:
        condition: service_healthy
    networks:
      - ai-va-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5173 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s

  # MinIO service for attachments (optional - use profile 'attachments')
  minio:
    image: quay.io/minio/minio:latest
    container_name: minio-dev
    restart: unless-stopped
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minio_rag_user}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD:-minio_rag_password}
    ports:
      - '${MINIO_PORT:-9000}:9000'
      - '${MINIO_CONSOLE_PORT:-9001}:9001'
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - ai-va-network
    profiles:
      - attachments
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9000/minio/health/live || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

volumes:
  pgdata:
  minio_data:
  ollama:
  llama:
  llamadist:

networks:
  ai-va-network:
    driver: bridge
